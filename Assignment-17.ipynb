{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a790e9-0d5e-44c8-abd4-ceb71dffa2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                                 ques - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafce6a-c1a1-4da0-b270-8c8ac24f03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format\n",
    "    which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "    \n",
    "    web scraping is basically used to scrap data from websites for different purpose like to study of those data, and many more reasons.\n",
    "    \n",
    "    different areas where web scraping is used : \n",
    "    1. Market Research\n",
    "    2. Price Monitoring\n",
    "    3. News Monitoring\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc9715-92ad-47ff-a8f0-42235b4d741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                                ques - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd6e89-dae7-403a-800c-48075b2d492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" different methods used for scrapping are :\n",
    "    1. online services\n",
    "    2. particular API's\n",
    "    3. creating own scraping code from scratch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad557449-6abc-41e5-b7e4-db8d377633d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                                ques - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bac5a7-61db-4757-92fc-95926268c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, \n",
    "    i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML\n",
    "    , which is useful for web scraping\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686d797-77d8-4dc5-99ee-e603e4f4a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                                ques - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065663e0-11bc-445f-bcb0-76d91226d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" because Flask is a lightweight framework to build websites and to collect data and show the scraped data as html or xml file of another\n",
    "    page.The requests module allows us to send http requests to the website we want to scrape.\n",
    "    so with the help of flask framwork it is easy to make web scraper because of its modules and it is also used for lightweight websites\n",
    "    that's why we have used flask.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de49e646-d98d-48de-b90b-ad0c77615afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                                ques - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663d7800-e15b-4254-a3ee-fb188b5dc286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" we have used two services of Aws console i.e \n",
    "    1. Codepipline\n",
    "    2. Elastic Beanstalk\n",
    "    \n",
    "1. codepipline : code pipline is used in Aws(Amazon web services) to get the code from github to elastic beanstalk .i.e server environment.\n",
    "\n",
    "2. Elastic Beanstalk : Elastic beanstalk is used to autometically deploy the code to the server and also manage the health and monitor the \n",
    "                       performance of the application on the server. and can perform many action like scaling the web application.\n",
    "                       \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
