{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37b6642c-1656-43b6-9d48-4ca7be543238",
   "metadata": {},
   "source": [
    "# Ques - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723eb1b-d227-415d-a8fc-002f6e17a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The assumnptions use in Annova test are following : \n",
    "    1. Normalty in the sampling distribution of means\n",
    "    2. Absence of outliers.\n",
    "    3. Homoginity of varience (same varience)\n",
    "    4. Samples are independents and Random.\n",
    "    \n",
    "    Example for voilition of the Assumption of Anova test on the result :\n",
    "    \n",
    "    1 . Normality in the sampling : \n",
    "    if there are only a small number of data points, nonnormality can be hard to detect.\n",
    "    If there are a great many data points, the normality test may detect statistically \n",
    "    significant but trivial departures from normality that will have no real effect on\n",
    "    the F statistic.\n",
    "    For data sampled from a normal distribution,The one-way ANOVA's F test will not be\n",
    "    much affected even if the population distributions are skewed, but the F test can be\n",
    "    sensitive to population skewness if the sample sizes are seriously unbalanced. If the sample\n",
    "    sizes are not unbalanced, the F test will not be seriously affected by light-tailedness\n",
    "    or heavy-tailedness, unless the sample sizes are small (less than 5), or the departure \n",
    "    from normality is extreme (kurtosis less than -1 or greater than 2).\n",
    "    \n",
    "    2. Absence of outliers : \n",
    "    Outliers tend to increase the estimate of sample variance, thus decreasing the calculated\n",
    "    F statistic for the ANOVA and lowering the chance of rejecting the null hypothesis. \n",
    "    \n",
    "    3. Hompginity of varience : \n",
    "    The effect of inequality of variances is mitigated when the sample sizes are equal: The \n",
    "    F test is fairly robust against inequality of variances if the sample sizes are equal,\n",
    "    although the chance increases of incorrectly reporting a significant difference in the\n",
    "    means when none exists. This chance of incorrectly rejecting the null hypothesis is greater\n",
    "    when the population variances are very different from each other, particularly if there is \n",
    "    one sample variance very much larger than the others.\n",
    "    \n",
    "    4. Samples are independents or random : \n",
    "    correlated samples, such as a set of observations over time on the same subjects, are not\n",
    "    independent, and such data would be more appropriately tested by a one-way blocked ANOVA \n",
    "    or a repeated measures ANOVA.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16988bcb-4e6d-4f5e-a229-307cd2917263",
   "metadata": {},
   "source": [
    "# Ques - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cfc29-585c-4b07-bcbe-31f93385d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The three types of Anova are : \n",
    "    1. one - way Anova\n",
    "    2. two - way Anova\n",
    "    3. repeated measures Anova\n",
    "    \n",
    "    1. Use a one-way ANOVA when you have collected data about one categorical independent variable\n",
    "    and one quantitative dependent variable. The independent variable should have at least three\n",
    "    levels (i.e. at least three different groups or categories).\n",
    "    \n",
    "    2. A two-way ANOVA is an extension of the one-way ANOVA. With a one-way, you have one independent\n",
    "    variable affecting a dependent variable. With a two-way ANOVA, there are two independents.\n",
    "    \n",
    "    3. A repeated measures ANOVA is used to determine whether or not there is a statistically \n",
    "    significant difference between the means of three or more groups in which the same subjects\n",
    "    show up in each group.\n",
    "    it is measured under two conditions :\n",
    "    < a > Measuring the mean scores of subjects during three or more time points.\n",
    "    < b > Measuring the mean scores of subjects under three different conditions. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857bd31-5d37-4da8-a8bd-e6757f2175e9",
   "metadata": {},
   "source": [
    "# Ques - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262bbfc2-d595-46c8-ad81-18070c74fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" An ANOVA uses an F-test to evaluate whether the variance among the groups is greater than the \n",
    "    variance within a group. Another way to view this problem is that we could partition variance,\n",
    "    that is, we could divide the total variance in our data into the various sources of that variation.\n",
    "    Partitioning variance is an incredibly important concept within statistics. For scientists,\n",
    "    it is a useful way of looking at the world: variation is everywhere, and we want to know the\n",
    "    relative contributions of all the sources of variation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c29e5-8c28-4e3a-8e98-effb691c2e87",
   "metadata": {},
   "source": [
    "# Ques - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb40073d-0d0a-49ed-a0f9-7f62e1e88c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331.07488479262696\n",
      "917.4751152073725\n",
      "1248.5499999999995\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\"\"\" in python there is a library called statsmodel.api in which there is funtion \n",
    "    which is used to calculate the regression.\"\"\"\n",
    "# first we have to create the data\n",
    "# then we will use the OLS function() to fit a simple linear regression model.\n",
    "# then we will calculate the SST,SSR,SSE of the data.\n",
    "df = pd.DataFrame({'hours': [1, 1, 1, 2, 2, 2, 2, 2, 3, 3,\n",
    "                             3, 4, 4, 4, 5, 5, 6, 7, 7, 8],\n",
    "                   'score': [68, 76, 74, 80, 76, 78, 81, 84, 86, 83,\n",
    "                             88, 85, 89, 94, 93, 94, 96, 89, 92, 97]})\n",
    "y = df['score']\n",
    "x = df[['hours']]\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "#calculate sse\n",
    "sse = np.sum((model.fittedvalues - df.score)**2)\n",
    "print(sse)\n",
    "\n",
    "#calculate ssr\n",
    "ssr = np.sum((model.fittedvalues - df.score.mean())**2)\n",
    "print(ssr)\n",
    "\n",
    "#calculate sst\n",
    "sst = ssr + sse\n",
    "print(sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01773604-fb35-4718-bc46-14bf86ad2870",
   "metadata": {},
   "source": [
    "# Ques - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b546142-250a-41bc-a396-9d8de5effab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(water)</th>\n",
       "      <td>8.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(sun)</th>\n",
       "      <td>24.866667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.3125</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(water):C(sun)</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3125</td>\n",
       "      <td>0.120667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>12.800000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sum_sq    df        F    PR(>F)\n",
       "C(water)          8.533333   1.0  16.0000  0.000527\n",
       "C(sun)           24.866667   2.0  23.3125  0.000002\n",
       "C(water):C(sun)   2.466667   2.0   2.3125  0.120667\n",
       "Residual         12.800000  24.0      NaN       NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" To calculate the main effect and interactiion effect using two - way Anova using python : \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#create data\n",
    "df = pd.DataFrame({'water': np.repeat(['daily', 'weekly'], 15),\n",
    "                   'sun': np.tile(np.repeat(['low', 'med', 'high'], 5), 2),\n",
    "                   'height': [6, 6, 6, 5, 6, 5, 5, 6, 4, 5,\n",
    "                              6, 6, 7, 8, 7, 3, 4, 4, 4, 5,\n",
    "                              4, 4, 4, 4, 4, 5, 6, 6, 7, 8]})\n",
    "model = ols('height ~ C(water) + C(sun) + C(water):C(sun)', data=df).fit()\n",
    "sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da27b19-612f-4a6a-b5a6-dfd8d5c067da",
   "metadata": {},
   "source": [
    "# Ques - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d7d5e-9893-4149-8bab-6b977a945be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from the one way anova test with f_test_vallue = 5.24 and p_value = 0.02\n",
    "    we can conclude about the difference between the groups, which is \n",
    "    if we take alpha = 0.05(commom) then our p_value is less than the alpha, so we \n",
    "    can say that we can reject the null hypothesis.\n",
    "    and can say about the difference between the group is that not all the samples(groups)\n",
    "    have same mean or atleast one group has different mean.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd669d-32cf-4c74-8e03-9caf37806891",
   "metadata": {},
   "source": [
    "# Ques - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329ce46-838d-4d40-bb7b-187df801a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Handling missing data in a repeated measures ANOVA is important because the presence ofmissing values\n",
    "    can affect the validity and reliability of the analysis.\n",
    "    There are multiple method for handiling this situation :\n",
    "    \n",
    "    1. Complete Case Analysis : This method involves excluding anyparticipant with missing data from\n",
    "    the analysis. It is the simplest approach, but itmay lead to a loss of valuable information,\n",
    "    reduced statistical power, and potentialbias if the missingness is related to the outcome\n",
    "    variable or other factors.\n",
    "    \n",
    "    2. Mean Imputation : This method replaces missing values with the mean of theobserved values for that variable.\n",
    "    \n",
    "    3. Last Observation Carried Forward  : This method carries the last observed value forward for missing\n",
    "    data points. LOCF can introduce bias if there is a trend orsystematic change in the data over time.\n",
    "    \n",
    "    4. Multiple Imputation : Multiple imputation creates multiple plausible imputeddatasets based on the\n",
    "    observed data. It estimates the missing values multiple times,incorporating uncertainty due to \n",
    "    missing data. This method provides more accurateestimates and standard errors, but it requires more\n",
    "    complex analysis.\n",
    "    \n",
    "    5. Model-Based Imputation : This approach uses statistical models to predict missing values based\n",
    "    on observed data. Model-based imputation can be more accurate thansimple mean imputation but may \n",
    "    still introduce bias if the model is misspecified.\n",
    "    \n",
    "    Potential consequences of using different methods : \n",
    "    \n",
    "    1. Biased Estimates : Some methods, like mean imputation and LOCF, can introducebias in the \n",
    "    estimated group means and treatment effects if the missing datamechanism is not missing \n",
    "    completely at random (MCAR)\n",
    "    \n",
    "    2. Loss of Power : Complete case analysis can result in reduced statistical power dueto the \n",
    "    loss of participants with missing data, especially if the missingness is relatedto the outcome variable.\n",
    "    \n",
    "    3. Inflated Type I Error :  Ignoring missing data or using inappropriate imputationmethods can\n",
    "    lead to inflated Type I error rates, resulting in false-positive findings.\n",
    "    \n",
    "    4. Underestimation of Variability :  Improper handling of missing data canunderestimate within-subject\n",
    "    variability, leading to wider confidence intervals andpotentially failing to detect true treatment effects.\n",
    "    \n",
    "    5. Decreased Precision : Inaccurate or inefficient handling of missing data can reducethe precision \n",
    "    of parameter estimates and make the results less reliable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3585d779-4565-4e12-9aa9-cdc9c68051ec",
   "metadata": {},
   "source": [
    "# Ques - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d846bcd-81ea-43a4-80c6-f75dc37ab5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  post-hoc tests are often used to identifywhich specic groups differ from each other.\n",
    "     Post-hoc tests help to perform multiple pairwisecomparisons and control the family-wise error rate,\n",
    "     which is the probability of making at leastone Type I error (false positive) among all the comparisons.\n",
    "     \n",
    "     Some common post-hoc tests used after ANOVA include:\n",
    "     \n",
    "     1. Tukey's Honestly Significant Difference (HSD) : Tukey's HSD test is one of themost widely used \n",
    "     post-hoc tests. It compares all possible pairs of group means anddetermines whether their differences\n",
    "     are significant.\n",
    "     \n",
    "     2. Bonferroni correction : Bonferroni correction is a simple method to control thefamily-wise error rate.\n",
    "     It divides the desired significance level by the number of comparisons being made.\n",
    "     Each individual comparison's p-value must be less than or equal to the adjusted significance \n",
    "     level for significance.This correction is often used when you have a small number of planned comparisons.\n",
    "     \n",
    "     3. Scheffe's method : Scheffe's test is a conservative post-hoc test that is used whensample sizes are \n",
    "     unequal and variances are not necessarily equal. It controls thefamily-wise error rate for all possible\n",
    "     linear combinations of group means.\n",
    "     \n",
    "     4. Fisher's Least Significant Difference : Fisher's LSD test is relatively lessconservative than \n",
    "     Tukey's HSD, making it useful when sample sizes are equal, and variances are equal or approximately\n",
    "     equal. It is a good choice when there is aspecific hypothesis about which groups to compare.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6969c17-df74-48f3-99d9-e9c06dfa1642",
   "metadata": {},
   "source": [
    "# Ques - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea160e4-fb9f-4fe2-b8d3-499052fb589d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7409240924092408, 0.18696068731600465)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "diet_A = [2,3,4,5,6,2,1,9,7,9,7,6,3,4,7,2]\n",
    "\n",
    "\n",
    "diet_B = [1,1,6,2,8,7,3,3,1,4,3,8,9,3,1,4]\n",
    "\n",
    "\n",
    "diet_C = [9,5,6,7,9,9,1,8,3,9,3,3,9,7,3,2]\n",
    "\n",
    "all_data = [np.array(diet_A),np.array(diet_B),np.array(diet_C)]\n",
    "\n",
    "f_stat,p_value = f_oneway(*all_data)\n",
    "f_stat,p_value\n",
    "\"\"\" if p_value is less than the significane level that means we reject the null hypothesis and\n",
    "    conclude that there is significant difference between the mean of these group\n",
    "    otherwise we accept the null hypothesis and cannot conclude that there is difference \n",
    "    between mean of the three groups.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995db7b1-6519-4a37-97e5-485f4231ee17",
   "metadata": {},
   "source": [
    "# Ques - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505bdaa6-0dec-45e6-af64-fdb0e74fdbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.752352236138195,\n",
       " 0.0007945115709784991,\n",
       " 0.50474438153198,\n",
       " 0.48427001563135097,\n",
       " 0.511794472420521,\n",
       " 0.6058145945473807)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = pd.DataFrame({\"Time\" : [12.3, 13.1, 11.5, 10.8, 13.5, 12.9, 9.7, 11.2, 10.4, 11.6, \n",
    "                    14.2, 13.9, 15.1, 14.8, 15.9, 16.3, 17.0, 16.2, 13.8, 14.4, 11.9,\n",
    "                    11.6, 10.5, 9.8, 10.1, 12.7, 12.4, 14.5, 13.7, 15.2],\n",
    "                    \n",
    "                    \"Program\" : [\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"B\",\"B\",\"B\",\"B\",\"C\",\"C\",\"C\",\"C\",\n",
    "                                \"C\",\"C\",\"A\",\"A\",\"A\",\"A\",\"B\",\"B\",\"B\",\"B\",\"C\",\"C\",\"C\",\"C\",\n",
    "                                \"C\",\"C\"],\n",
    "                    \"Experience\" : [\"Novice\",\"Novice\",\"Experienced\",\"Experienced\",\"Novice\",\n",
    "                                \"Novice\",\"Experienced\",\"Experienced\",\"Novice\",\"Experienced\",\n",
    "                                   \"Novice\",\"Novice\",\"Experienced\",\"Experienced\",\"Experienced\",\n",
    "                                    \"Experienced\",\"Experienced\",\"Experienced\",\"Experienced\",\n",
    "                                    \"Experienced\", \"Novice\",\"Novice\",\"Novice\",\"Experienced\",\n",
    "                                    \"Experienced\",\"Experienced\", \"Novice\",\"Experienced\",\n",
    "                                    \"Experienced\",\"Experienced\"]})\n",
    "\n",
    "model = ols('Time ~ Program + Experience + Program:Experience',data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "F_program = anova_table['F']['Program']\n",
    "F_experience = anova_table['F']['Experience']\n",
    "F_interaction = anova_table['F']['Program:Experience']\n",
    "\n",
    "p_program = anova_table['PR(>F)']['Program']\n",
    "p_experience = anova_table['PR(>F)']['Experience']\n",
    "p_interaction = anova_table['PR(>F)']['Program:Experience']\n",
    "\n",
    "F_program,p_program,F_experience,p_experience,F_interaction,p_interaction \n",
    "\n",
    "\"\"\" Main Effect of Software Program :\n",
    "\n",
    "    If p_program is less than the chosen significance level (e.g., 0.05), we reject the nullhypothesis and \n",
    "    conclude that there are significant differences in the average timeacross the software programs.\n",
    "    \n",
    "    Main Effect of Employee Experience : \n",
    "    If p_experience is less than the chosen significance level (e.g., 0.05), we reject thenull hypothesis\n",
    "    and conclude that there are significant differences in the averagetime between novice and experienced employees\n",
    "    \n",
    "    Interaction Effect between Software Program and Employee Experience : \n",
    "    If p_interaction is less than the chosen significance level (e.g., 0.05), we reject thenull hypothesis\n",
    "    and conclude that there is a significant interaction effect.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91cc8e-7d1f-46a8-84f7-8a90e65b7875",
   "metadata": {},
   "source": [
    "# Ques - 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56ef77d-040c-4817-aacc-6ca36e797826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.393098704677211 5.755655840190321e-17\n",
      "There is a significant difference between scores of the groups\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj lower   upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental     10.4   0.0 8.9372 11.8628   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "control_scores = [70,72,68,65,74,71,69,75,68,73, 72,70,75,71,69,70,71,73,68,72]\n",
    "\n",
    "experimental_scores = [80,82,79,85,81,83,78,82,79,84, 82,80,83,79,80,81,84,82,79,81]\n",
    "\n",
    "t_stat, p_value = ttest_ind(control_scores, experimental_scores)\n",
    "print(t_stat,p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"There is a significant difference between scores of the groups\")\n",
    "else:\n",
    "    print(\"There is no significant difference between scores of the groups\")\n",
    "    \n",
    "if p_value <0.05:\n",
    "    all_scores = np.array(control_scores + experimental_scores)\n",
    "    group_indicator = np.array([\"Control\"] *len(control_scores) + [\"Experimental\"] *len(experimental_scores))\n",
    "    data = pd.DataFrame({\"Scores\": all_scores,\"Group\":group_indicator})\n",
    "    posthoc = MultiComparison(data[\"Scores\"], data[\"Group\"])\n",
    "    result = posthoc.tukeyhsd()\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919eec4-081a-49c9-b0c7-4fded9dfab93",
   "metadata": {},
   "source": [
    "# Ques - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c171022-b1b1-424e-92c4-559996670083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.72352941176479\n",
      "p-value: 1.839617085900212e-18\n",
      "There is a significant difference in average daily sales between the three stores.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1  group2  meandiff p-adj    lower    upper   reject\n",
      "----------------------------------------------------------\n",
      "Store A Store B  206.6667    0.0   151.672 261.6613   True\n",
      "Store A Store C     -45.0 0.1307  -99.9946   9.9946  False\n",
      "Store B Store C -251.6667    0.0 -306.6613 -196.672   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "store_A_sales = [1000,1200,900,1100,950,1050,1150,1000,1050,1100, 900,1150,1200,950,1000,1100,\n",
    "                 1050,950,1150,1000, 1200,900,1100,950,1050,1150,1000,1050,1100,900]\n",
    "\n",
    "store_B_sales = [1300,1250,1350,1200,1100,1400,1150,1300,1250,1350, 1200,1100,1400,1150,1300,\n",
    "                 1250,1350,1200,1100,1400,1150,1300,1250,1350,1200,1100,1400,1150,1300,1250]\n",
    "\n",
    "store_C_sales = [950,1000,900,1050,1100,950,1000,900,1050,1100, 950,1000,900,1050,1100,950,\n",
    "                 1000,900,1050,1100, 950,1000,900,1050,1100,950,1000,900,1050,1100]\n",
    "\n",
    "all_sales = [np.array(store_A_sales), np.array(store_B_sales),np.array(store_C_sales)]\n",
    "f_statistic, p_value = f_oneway(*all_sales)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"There is a significant difference in average daily sales between the three stores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in average daily sales between the three stores.\")\n",
    "    \n",
    "if p_value <0.05:\n",
    "    all_data = np.concatenate(all_sales)\n",
    "    group_indicator = np.array([\"Store A\"] *len(store_A_sales) +[\"Store B\"] *len(store_B_sales) +\n",
    "                               [\"Store C\"] *len(store_C_sales))\n",
    "    data = pd.DataFrame({\"Sales\": all_data,\"Store\": group_indicator})\n",
    "    posthoc = MultiComparison(data[\"Sales\"], data[\"Store\"])\n",
    "    result = posthoc.tukeyhsd()\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
